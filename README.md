# ğŸ“œ Quotes Web Scraper (Life Quotes)

## ğŸ“¸ Sample Output
![Life Quotes Output](https://raw.githubusercontent.com/MohsinKhalidDar/web-scraping-quotes/main/screenshots/output_preview.png)

This project scrapes quotes from **https://quotes.toscrape.com**, filters quotes
tagged with **"life"**, and saves them into a clean CSV file.

The project is implemented as a **Jupyter Notebook** and demonstrates a complete
web-scraping pipeline: fetching data, handling pagination, retries, parsing HTML,
filtering content, and exporting structured data.

---

## ğŸš€ Features
- Pagination scraping (unknown number of pages)
- Retry logic for network failures
- User-Agent handling
- Raw HTML storage for reproducibility
- Data extraction using BeautifulSoup
- Clean CSV output using Pandas

---

## ğŸ›  Tech Stack
- Python
- Requests
- BeautifulSoup
- Pandas
- Jupyter Notebook

---

## ğŸ“‚ Project Structure
web-scraping-quotes/
â”‚

â”œâ”€â”€ quotes_scraper.ipynb

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ README.md

â”œâ”€â”€ scraped_data/

â”‚ â””â”€â”€ quotes1.html, quotes2.html, ...

â”œâ”€â”€ cleaned_data/

â”‚ â””â”€â”€ life_quotes.csv


---

## â–¶ How to Run the Jupyter Notebook

1ï¸âƒ£ Clone the Repository

git clone https://github.com/MohsinKhalidDar/web-scraping-quotes.git

cd web-scraping-quotes

ls


2ï¸âƒ£ Create a Virtual Environment(Optional) 
python -m venv venv


Activate it:

Windows

venv\Scripts\activate


Mac/Linux

source venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


4ï¸âƒ£ Launch Jupyter Notebook
jupyter notebook

5ï¸âƒ£ Run the Notebook

Open quotes_scraper.ipynb

Run all cells from top to bottom using:

Shift + Enter
 

### Pull Shark Achievement Test â€“ PR 1
### Pull Shark Achievement Test â€“ PR 2
